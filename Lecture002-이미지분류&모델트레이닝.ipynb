{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.anadronestarting.com/wp-content/uploads/intel-main_opt.png' width=50%>\n",
    "\n",
    "# Lecture002 - 이미지 분류 & 모델 트레이닝\n",
    "<font size=5><b>(Image Classification using Mobilenet)<b></font>\n",
    "\n",
    "<div align='right'>성  민  석 (Minsuk Sung)</div>\n",
    "<div align='right'>이  인  구 (Ike Lee)</div>    \n",
    "\n",
    "<img src='https://chaosmail.github.io/images/deep-learning/classification.png' width=60%>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>강의목차<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#필요한-라이브러리-및-옵션\" data-toc-modified-id=\"필요한-라이브러리-및-옵션-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>필요한 라이브러리 및 옵션</a></span><ul class=\"toc-item\"><li><span><a href=\"#기본-라이브러리(Library)\" data-toc-modified-id=\"기본-라이브러리(Library)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>기본 라이브러리(Library)</a></span></li><li><span><a href=\"#옵션(Option)\" data-toc-modified-id=\"옵션(Option)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>옵션(Option)</a></span></li></ul></li><li><span><a href=\"#예제---VOC2012\" data-toc-modified-id=\"예제---VOC2012-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>예제 - VOC2012</a></span><ul class=\"toc-item\"><li><span><a href=\"#VOC-2012란?\" data-toc-modified-id=\"VOC-2012란?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>VOC 2012란?</a></span></li><li><span><a href=\"#VOC-데이터의-구성\" data-toc-modified-id=\"VOC-데이터의-구성-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>VOC 데이터의 구성</a></span></li><li><span><a href=\"#다운로드-링크\" data-toc-modified-id=\"다운로드-링크-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>다운로드 링크</a></span></li><li><span><a href=\"#학습에-필요한-상수\" data-toc-modified-id=\"학습에-필요한-상수-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>학습에 필요한 상수</a></span></li><li><span><a href=\"#모델-컴파일\" data-toc-modified-id=\"모델-컴파일-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>모델 컴파일</a></span></li><li><span><a href=\"#모델-학습하기\" data-toc-modified-id=\"모델-학습하기-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>모델 학습하기</a></span></li><li><span><a href=\"#모델-저장하기\" data-toc-modified-id=\"모델-저장하기-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>모델 저장하기</a></span></li><li><span><a href=\"#모델-평가하기\" data-toc-modified-id=\"모델-평가하기-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>모델 평가하기</a></span></li><li><span><a href=\"#테스트해보기\" data-toc-modified-id=\"테스트해보기-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>테스트해보기</a></span></li></ul></li><li><span><a href=\"#참고\" data-toc-modified-id=\"참고-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>참고</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 및 옵션\n",
    "\n",
    "### 기본 라이브러리(Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:28.994832Z",
     "start_time": "2019-12-02T14:36:28.983647Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:29.526976Z",
     "start_time": "2019-12-02T14:36:28.997413Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:29.714954Z",
     "start_time": "2019-12-02T14:36:29.528764Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:30.483839Z",
     "start_time": "2019-12-02T14:36:29.716050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist,cifar10\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet, MobileNetV2\n",
    "from tensorflow.keras.models import Model,Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Conv2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras.losses import categorical_crossentropy,binary_crossentropy\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옵션(Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:30.613864Z",
     "start_time": "2019-12-02T14:36:30.484987Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 150647114324605899\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9867543121520394435\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "%matplotlib inline\n",
    "print(device_lib.list_local_devices())\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 예제 - VOC2012\n",
    "\n",
    "![](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/pascal2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> VOC 2012 데이터는 한 이미지 내에 여러가지 객체가 존재합니다. 그래서 기존의 방법과는 조금 다르게 접근해야합니다.  \n",
    "아래 코드를 따라가봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 CLASSES 의 사물과 Lecture001 에서 모은 사물들의 이름이 일치해야 합니다.\n",
    "ex) VOC4IC/train 아래 사물들의 이름과 클래스 이름들이 같아야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:30.617087Z",
     "start_time": "2019-12-02T14:36:30.614844Z"
    }
   },
   "outputs": [],
   "source": [
    "# 우리가 분류할 20개의 클래스\n",
    "\n",
    "CLASSES = [ 'cup', '계산기', 'book'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습에 필요한 상수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:30.621898Z",
     "start_time": "2019-12-02T14:36:30.618645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/VOC2012/JPEGImages\n",
      "data/VOC2012/Annotations\n"
     ]
    }
   ],
   "source": [
    "# 학습에 필요한 상수들을 정의 합니다. \n",
    "\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "\n",
    "# 각 이미지의 기본 주소\n",
    "BASE_PATH = './data/VOC2012/JPEGImages/'\n",
    "images_dir = Path(BASE_PATH).expanduser()\n",
    "print(images_dir)\n",
    "\n",
    "# 각 이미지별 클래스의 기본 주소\n",
    "XML_BASE_PATH = './data/VOC2012/Annotations/'\n",
    "annotations_dir = Path(XML_BASE_PATH).expanduser()\n",
    "print(annotations_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:31.561582Z",
     "start_time": "2019-12-02T14:36:31.557588Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터의 레이블을 정리 합니다 \n",
    "\n",
    "def xml_to_labels(xml_data, unique_labels):\n",
    "    root = ET.XML(xml_data)\n",
    "    labels = set() if unique_labels else []\n",
    "    labels_add = labels.add if unique_labels else labels.append # speeds up method lookup\n",
    "    for i, child in enumerate(root):\n",
    "        if child.tag == 'filename':\n",
    "            img_filename = child.text\n",
    "        if child.tag == 'object':\n",
    "            for subchild in child:\n",
    "                if subchild.tag == 'name':\n",
    "                    labels_add(subchild.text)\n",
    "    return img_filename, list(labels)\n",
    "\n",
    "def get_labels(annotations_dir, unique_labels=True):\n",
    "    for annotation_file in annotations_dir.iterdir():\n",
    "        with open(annotation_file) as f:\n",
    "            yield xml_to_labels(f.read(), unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NanumGothic']\n"
     ]
    }
   ],
   "source": [
    "# 한글폰트 인식을 위해 설치해줍니다.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='NanumGothic')\n",
    "print(plt.rcParams['font.family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:44.072012Z",
     "start_time": "2019-12-02T14:36:43.912394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book     68\n",
      "계산기     124\n",
      "cup     171\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 우리가 모델 훈련에 사용할 데이터 내용 입니다.\n",
    "\n",
    "class_list = []\n",
    "num_list = []\n",
    "\n",
    "IMAGE_BASE_PATH = './data/VOC4IC/'\n",
    "train_path = IMAGE_BASE_PATH + 'train/'\n",
    "for folder in os.listdir(train_path):\n",
    "    folder_size = len(os.listdir(train_path+folder))\n",
    "#     print('{:<15} : {}'.format(folder,folder_size))\n",
    "    class_list.append(folder)\n",
    "    num_list.append(folder_size)\n",
    "    \n",
    "voc_s = pd.Series(num_list,index=class_list)\n",
    "voc_s.sort_values().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "print(voc_s.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book    22\n",
      "계산기     41\n",
      "cup     57\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 우리가 모델 훈련 검증에 사용할 데이터 내용 입니다.\n",
    "\n",
    "class_list = []\n",
    "num_list = []\n",
    "\n",
    "IMAGE_BASE_PATH = './data/VOC4IC/'\n",
    "valid_path = IMAGE_BASE_PATH + 'valid/'\n",
    "for folder in os.listdir(valid_path):\n",
    "    folder_size = len(os.listdir(valid_path+folder))\n",
    "#     print('{:<15} : {}'.format(folder,folder_size))\n",
    "    class_list.append(folder)\n",
    "    num_list.append(folder_size)\n",
    "    \n",
    "voc_s = pd.Series(num_list,index=class_list)\n",
    "voc_s.sort_values().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "print(voc_s.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:44.285382Z",
     "start_time": "2019-12-02T14:36:44.073088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book    23\n",
      "계산기     41\n",
      "cup     57\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 우리가 훈련된 모델을 검증하는데 사용할 데이터 내용 입니다.\n",
    "\n",
    "class_list = []\n",
    "num_list = []\n",
    "\n",
    "IMAGE_BASE_PATH = './data/VOC4IC/'\n",
    "test_path = IMAGE_BASE_PATH + 'test/'\n",
    "for folder in os.listdir(test_path):\n",
    "    folder_size = len(os.listdir(test_path+folder))\n",
    "#     print('{:<15} : {}'.format(folder,folder_size))\n",
    "    class_list.append(folder)\n",
    "    num_list.append(folder_size)\n",
    "    \n",
    "voc_s = pd.Series(num_list,index=class_list)\n",
    "voc_s.sort_values().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "print(voc_s.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning 을 통해 적은 데이터를 가지고 빠르게 학습시키기\n",
    "\n",
    "여기서는 VOC2012에서 학습한 weight(가중치) 값을 이용하여 VOC4IC 데이터를 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:48.471330Z",
     "start_time": "2019-12-02T14:36:44.286500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/intel/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# base model 의 input shape, 그리고  trainable 을 false 로 합니다. \n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224,224,3),\n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning 에서 정확성을 높이기 위해 마지막 3개 block 에서 모델 트레이닝합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:48.479155Z",
     "start_time": "2019-12-02T14:36:48.472416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:00<00:00, 31665.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# transfer learning에서 마지막 3개 block 을 사용하여 모델을 트레이닝 합니다. \n",
    "\n",
    "set_trainable = False\n",
    "for layer in tqdm(base_model.layers):\n",
    "    if layer.name in ['block_14_expand','block_15_expand', 'block_16_expand']:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:48.489086Z",
     "start_time": "2019-12-02T14:36:48.480044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;tensorflow.python.keras.engine.input_layer.In...</td>\n",
       "      <td>input_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>Conv1_pad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>Conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>bn_Conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>Conv1_relu</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>expanded_conv_depthwise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>expanded_conv_depthwise_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>expanded_conv_depthwise_relu</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>expanded_conv_project</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>expanded_conv_project_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_1_expand</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_1_expand_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_1_expand_relu</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_1_pad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_1_depthwise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_1_depthwise_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_1_depthwise_relu</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_1_project</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_1_project_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_2_expand</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_2_expand_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_2_expand_relu</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_2_depthwise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_2_depthwise_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_2_depthwise_relu</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_2_project</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_2_project_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Add obje...</td>\n",
       "      <td>block_2_add</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_3_expand</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_3_expand_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_13_project_BN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_14_expand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_14_expand_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_14_expand_relu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_14_depthwise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_14_depthwise_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_14_depthwise_relu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_14_project</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_14_project_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Add obje...</td>\n",
       "      <td>block_14_add</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_15_expand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_15_expand_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_15_expand_relu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_15_depthwise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_15_depthwise_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_15_depthwise_relu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_15_project</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_15_project_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.merge.Add obje...</td>\n",
       "      <td>block_15_add</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_16_expand</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_16_expand_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_16_expand_relu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_16_depthwise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_16_depthwise_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>block_16_depthwise_relu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>block_16_project</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>block_16_project_BN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.convolutional....</td>\n",
       "      <td>Conv_1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.normalization....</td>\n",
       "      <td>Conv_1_bn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>out_relu</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Layer Type  \\\n",
       "0    <tensorflow.python.keras.engine.input_layer.In...   \n",
       "1    <tensorflow.python.keras.layers.convolutional....   \n",
       "2    <tensorflow.python.keras.layers.convolutional....   \n",
       "3    <tensorflow.python.keras.layers.normalization....   \n",
       "4    <tensorflow.python.keras.layers.advanced_activ...   \n",
       "5    <tensorflow.python.keras.layers.convolutional....   \n",
       "6    <tensorflow.python.keras.layers.normalization....   \n",
       "7    <tensorflow.python.keras.layers.advanced_activ...   \n",
       "8    <tensorflow.python.keras.layers.convolutional....   \n",
       "9    <tensorflow.python.keras.layers.normalization....   \n",
       "10   <tensorflow.python.keras.layers.convolutional....   \n",
       "11   <tensorflow.python.keras.layers.normalization....   \n",
       "12   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "13   <tensorflow.python.keras.layers.convolutional....   \n",
       "14   <tensorflow.python.keras.layers.convolutional....   \n",
       "15   <tensorflow.python.keras.layers.normalization....   \n",
       "16   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "17   <tensorflow.python.keras.layers.convolutional....   \n",
       "18   <tensorflow.python.keras.layers.normalization....   \n",
       "19   <tensorflow.python.keras.layers.convolutional....   \n",
       "20   <tensorflow.python.keras.layers.normalization....   \n",
       "21   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "22   <tensorflow.python.keras.layers.convolutional....   \n",
       "23   <tensorflow.python.keras.layers.normalization....   \n",
       "24   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "25   <tensorflow.python.keras.layers.convolutional....   \n",
       "26   <tensorflow.python.keras.layers.normalization....   \n",
       "27   <tensorflow.python.keras.layers.merge.Add obje...   \n",
       "28   <tensorflow.python.keras.layers.convolutional....   \n",
       "29   <tensorflow.python.keras.layers.normalization....   \n",
       "..                                                 ...   \n",
       "125  <tensorflow.python.keras.layers.normalization....   \n",
       "126  <tensorflow.python.keras.layers.convolutional....   \n",
       "127  <tensorflow.python.keras.layers.normalization....   \n",
       "128  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "129  <tensorflow.python.keras.layers.convolutional....   \n",
       "130  <tensorflow.python.keras.layers.normalization....   \n",
       "131  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "132  <tensorflow.python.keras.layers.convolutional....   \n",
       "133  <tensorflow.python.keras.layers.normalization....   \n",
       "134  <tensorflow.python.keras.layers.merge.Add obje...   \n",
       "135  <tensorflow.python.keras.layers.convolutional....   \n",
       "136  <tensorflow.python.keras.layers.normalization....   \n",
       "137  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "138  <tensorflow.python.keras.layers.convolutional....   \n",
       "139  <tensorflow.python.keras.layers.normalization....   \n",
       "140  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "141  <tensorflow.python.keras.layers.convolutional....   \n",
       "142  <tensorflow.python.keras.layers.normalization....   \n",
       "143  <tensorflow.python.keras.layers.merge.Add obje...   \n",
       "144  <tensorflow.python.keras.layers.convolutional....   \n",
       "145  <tensorflow.python.keras.layers.normalization....   \n",
       "146  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "147  <tensorflow.python.keras.layers.convolutional....   \n",
       "148  <tensorflow.python.keras.layers.normalization....   \n",
       "149  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "150  <tensorflow.python.keras.layers.convolutional....   \n",
       "151  <tensorflow.python.keras.layers.normalization....   \n",
       "152  <tensorflow.python.keras.layers.convolutional....   \n",
       "153  <tensorflow.python.keras.layers.normalization....   \n",
       "154  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "\n",
       "                       Layer Name  Layer Trainable  \n",
       "0                         input_1            False  \n",
       "1                       Conv1_pad            False  \n",
       "2                           Conv1            False  \n",
       "3                        bn_Conv1            False  \n",
       "4                      Conv1_relu            False  \n",
       "5         expanded_conv_depthwise            False  \n",
       "6      expanded_conv_depthwise_BN            False  \n",
       "7    expanded_conv_depthwise_relu            False  \n",
       "8           expanded_conv_project            False  \n",
       "9        expanded_conv_project_BN            False  \n",
       "10                 block_1_expand            False  \n",
       "11              block_1_expand_BN            False  \n",
       "12            block_1_expand_relu            False  \n",
       "13                    block_1_pad            False  \n",
       "14              block_1_depthwise            False  \n",
       "15           block_1_depthwise_BN            False  \n",
       "16         block_1_depthwise_relu            False  \n",
       "17                block_1_project            False  \n",
       "18             block_1_project_BN            False  \n",
       "19                 block_2_expand            False  \n",
       "20              block_2_expand_BN            False  \n",
       "21            block_2_expand_relu            False  \n",
       "22              block_2_depthwise            False  \n",
       "23           block_2_depthwise_BN            False  \n",
       "24         block_2_depthwise_relu            False  \n",
       "25                block_2_project            False  \n",
       "26             block_2_project_BN            False  \n",
       "27                    block_2_add            False  \n",
       "28                 block_3_expand            False  \n",
       "29              block_3_expand_BN            False  \n",
       "..                            ...              ...  \n",
       "125           block_13_project_BN            False  \n",
       "126               block_14_expand             True  \n",
       "127            block_14_expand_BN             True  \n",
       "128          block_14_expand_relu             True  \n",
       "129            block_14_depthwise             True  \n",
       "130         block_14_depthwise_BN             True  \n",
       "131       block_14_depthwise_relu             True  \n",
       "132              block_14_project             True  \n",
       "133           block_14_project_BN             True  \n",
       "134                  block_14_add             True  \n",
       "135               block_15_expand             True  \n",
       "136            block_15_expand_BN             True  \n",
       "137          block_15_expand_relu             True  \n",
       "138            block_15_depthwise             True  \n",
       "139         block_15_depthwise_BN             True  \n",
       "140       block_15_depthwise_relu             True  \n",
       "141              block_15_project             True  \n",
       "142           block_15_project_BN             True  \n",
       "143                  block_15_add             True  \n",
       "144               block_16_expand             True  \n",
       "145            block_16_expand_BN             True  \n",
       "146          block_16_expand_relu             True  \n",
       "147            block_16_depthwise             True  \n",
       "148         block_16_depthwise_BN             True  \n",
       "149       block_16_depthwise_relu             True  \n",
       "150              block_16_project             True  \n",
       "151           block_16_project_BN             True  \n",
       "152                        Conv_1             True  \n",
       "153                     Conv_1_bn             True  \n",
       "154                      out_relu             True  \n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이어 구성을 살펴 봅니다. \n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in base_model.layers]\n",
    "\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:49.976485Z",
     "start_time": "2019-12-02T14:36:48.490018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               655872    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 2,946,883\n",
      "Trainable params: 688,899\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "# 모델 만들기, 기존 모델의 weight 값을 사용하고 pooling 과 activation 함수를 추가 합니다. \n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(len(CLASSES), activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "plot_model(model,to_file='./img/model/voc2012_mobilenet_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:50.038821Z",
     "start_time": "2019-12-02T14:36:49.977831Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(learning_rate=0.0001), # transfer learning 여기서 학습률을 더 작게 \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:50.152095Z",
     "start_time": "2019-12-02T14:36:50.039930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 363 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# 트레인 데이터 augmentation 의로 데이터를 증가 시킴니다.  \n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=30,\n",
    "                                   rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest'\n",
    "                                   )\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(IMAGE_BASE_PATH + 'train/',\n",
    "                                              target_size=(224, 224),\n",
    "                                              batch_size=8,\n",
    "                                              shuffle=True,\n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:50.513753Z",
     "start_time": "2019-12-02T14:36:50.157114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# 학습중에 validation에 사용할 데이터셋 입니다.  \n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_set = valid_datagen.flow_from_directory(IMAGE_BASE_PATH + 'valid/',\n",
    "                                            target_size=(224, 224),\n",
    "                                            batch_size=8,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:50.635869Z",
     "start_time": "2019-12-02T14:36:50.518433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# 학습을 완료후에 모델 성능 테스트에 사용할 데이터셋 입니다. \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(IMAGE_BASE_PATH + 'test/',\n",
    "                                            target_size=(224, 224),\n",
    "                                            batch_size=8,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:25.137510Z",
     "start_time": "2019-12-02T14:37:10.164914Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/45 [======>.......................] - ETA: 16s - loss: 1.0073 - acc: 0.5568"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-74bc30347ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#                               use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                               )\n",
      "\u001b[0;32m~/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/imobilenet/myvenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 트레이닝 입니다. \n",
    "\n",
    "history = model.fit_generator(train_set,\n",
    "                              steps_per_epoch=train_set.n // train_set.batch_size,\n",
    "                              epochs=30,\n",
    "                              validation_data=valid_set,\n",
    "                              validation_steps=valid_set.n // valid_set.batch_size,\n",
    "#                               use_multiprocessing=True,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:25.906887Z",
     "start_time": "2019-12-02T14:44:25.142704Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('./bin/mobilenetv2_class20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.class_indices.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:25.906887Z",
     "start_time": "2019-12-02T14:44:25.142704Z"
    }
   },
   "outputs": [],
   "source": [
    "# key 와 value 값을 바꾸어 줍니다. \n",
    "class20 = dict()\n",
    "for key,value in test_set.class_indices.items():\n",
    "    class20[value] = key\n",
    "\n",
    "with open('./bin/class20.pickle', 'wb') as f:\n",
    "    pickle.dump(class20, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:50.922359Z",
     "start_time": "2019-12-02T14:44:25.908502Z"
    }
   },
   "outputs": [],
   "source": [
    "# 트레인 데이터와 테스트 데이터 셋으로 loss 와 accuracy 측정합니다.  \n",
    "\n",
    "train_loss, train_acc = model.evaluate_generator(train_set)\n",
    "print('Train Loss : {}'.format(train_loss))\n",
    "print('Train Accuracy : {}'.format(train_acc))\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_set)\n",
    "print('Test Loss : {}'.format(test_loss))\n",
    "print('Test Accuracy : {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:51.054839Z",
     "start_time": "2019-12-02T14:44:50.923838Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss 측정값의 시각화 입니다.  \n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,loss,label='Training Loss')\n",
    "plt.plot(epochs,val_loss,label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:51.178139Z",
     "start_time": "2019-12-02T14:44:51.055902Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy 측정값의 시각화 입니다.  \n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,acc,label='Training Accuarcy')\n",
    "plt.plot(epochs,val_acc,label='Validation Accuarcy')\n",
    "plt.title('Training and Validation Accuarcy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:55.300576Z",
     "start_time": "2019-12-02T14:44:55.290471Z"
    }
   },
   "outputs": [],
   "source": [
    "# 추론하기 위한 작업입니다. 모델 설정, 입력 데이터 전처리.\n",
    "\n",
    "def predict_test_img(path):\n",
    "    img = cv2.imread(path) \n",
    "    \n",
    "    model = load_model('./bin/mobilenetv2_class20.h5')\n",
    "    \n",
    "    print('Original Shape : ',img.shape)\n",
    "    \n",
    "    img = cv2.resize(img, (224,224), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255\n",
    "    print('Resized Shape : ',img.shape)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    ans = model.predict_classes(np.expand_dims(img,axis=0))\n",
    "    with open('./bin/class20.pickle','rb') as f:\n",
    "        class20 = pickle.load(f)\n",
    "    print('Predict : {}'.format(class20[ans[0]]))\n",
    "    \n",
    "    predicted_result = model.predict(np.expand_dims(img,axis=0))\n",
    "\n",
    "    pd.DataFrame(predicted_result,columns=class20.values()).iloc[0].plot(kind='bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:45:43.591984Z",
     "start_time": "2019-12-02T14:45:33.879543Z"
    }
   },
   "outputs": [],
   "source": [
    "# 기존에 사용되지 않았던 임의 데이터를 추론 하기\n",
    "\n",
    "predict_test_img('img/test/dog.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:46:28.033589Z",
     "start_time": "2019-12-02T14:46:16.432395Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_test_img('img/test/cat.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "강의목차",
   "title_sidebar": "강의목차",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
